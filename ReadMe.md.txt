#Hackveda
#https://bit.ly/3y3zixE
#Khadeer Pasha

# Advanced-House-Price-Prediction
It is a Advanced Problem of Regression which requires advanced techniques of feature engineering, feature selection and extraction, modelling, model evaluation, and Statistics.

Start here if...
You have some experience with R or Python and machine learning basics. This is a perfect competition for data science students who have completed an online course in machine learning and are looking to expand their skill set before trying a featured competition. 

# Description

Practice Skills
Creative feature engineering 
Advanced regression techniques like random forest and gradient boosting
Acknowledgments
The Housing dataset.

# Goal
It is your job to predict the sales price for each house. For each Id in the test set, 
must predict the value of the SalePrice variable. 

# Metric
Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and 
the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and 
cheap houses will affect the result equally.)

# Python Tutorials
Fun with Real Estate Data
Use Rmarkdown to learn advanced regression techniques like random forests and XGBoost
XGBoost with Parameter Tuning
Implement LASSO regression to avoid multicollinearity
Includes linear regression, random forest, and XGBoost models as well
Ensemble Modeling: Stack Model Example
Use "ensembling" to combine the predictions of several models
Includes GBM (gradient boosting machine), XGBoost, ranger, and neural net using the caret package
A Clear Example of Overfitting
Learn about the dreaded consequences of overfitting data
Other Python Tutorials
Comprehensive Data Exploration with Python
Understand how variables are distributed and how they interact
Apply different transformations before training machine learning models
House Prices EDA
Learn to use visualization techniques to study missing data and distributions
Includes correlation heatmaps, pairplots, and t-SNE to help inform appropriate inputs to a linear model
A Study on Regression Applied to the Ames Dataset
Demonstrate effective tactics for feature engineering
Explore linear regression with different regularization methods including ridge, LASSO, and ElasticNet using scikit-learn
Regularized Linear Models
Build a basic linear model
Try more advanced algorithms including XGBoost and neural nets using Keras